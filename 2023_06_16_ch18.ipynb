{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVEqJeqki/b/iAyXIz0znw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiyuyeon/Ml_Dl/blob/master/2023_06_16_ch18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oecme6LolDcs",
        "outputId": "0c31a552-28a3-4f1b-b420-fb41af3820d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46 카테고리\n",
            "8982 학습용 뉴스 기사\n",
            "2246 테스트용 뉴스 기사\n",
            "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 2, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 2, 2, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 2, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.datasets import reuters       # 로이터 뉴스 데이터셋 불러오기\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 데이터를 불러와 학습셋, 테스트셋으로 나눕니다.\n",
        "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=1000, test_split=0.2)\n",
        "\n",
        "# 데이터를 확인해 보겠습니다.\n",
        "category = np.max(y_train) + 1\n",
        "print(category, '카테고리')\n",
        "print(len(X_train), '학습용 뉴스 기사')\n",
        "print(len(X_test), '테스트용 뉴스 기사')\n",
        "print(X_train[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어의 수를 맞추어 줍니다.\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=100)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=100)\n",
        "\n",
        "# 원-핫 인코딩 처리를 합니다.\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# 모델의 구조를 설정합니다.\n",
        "model = Sequential()\n",
        "model.add(Embedding(1000, 100))\n",
        "model.add(LSTM(100, activation='tanh'))\n",
        "model.add(Dense(46, activation='softmax'))\n",
        "\n",
        "# 모델의 실행 옵션을 정합니다.\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 학습의 조기 중단을 설정합니다.\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "# 모델을 실행합니다.\n",
        "history = model.fit(X_train, y_train, batch_size=20, epochs=200, validation_data=(X_test, y_test), callbacks=[early_stopping_callback])\n",
        "\n",
        "# 테스트 정확도를 출력합니다.\n",
        "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzP0FjOXumzC",
        "outputId": "ad5e7bf8-a06d-4fd3-9251-cbfcb86a3183"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "450/450 [==============================] - 44s 92ms/step - loss: 2.2254 - accuracy: 0.4388 - val_loss: 1.9830 - val_accuracy: 0.5205\n",
            "Epoch 2/200\n",
            "450/450 [==============================] - 40s 90ms/step - loss: 1.8114 - accuracy: 0.5473 - val_loss: 1.7164 - val_accuracy: 0.5672\n",
            "Epoch 3/200\n",
            "450/450 [==============================] - 40s 89ms/step - loss: 1.6289 - accuracy: 0.5845 - val_loss: 1.6036 - val_accuracy: 0.5917\n",
            "Epoch 4/200\n",
            "450/450 [==============================] - 41s 92ms/step - loss: 1.4961 - accuracy: 0.6183 - val_loss: 1.4839 - val_accuracy: 0.6318\n",
            "Epoch 5/200\n",
            "450/450 [==============================] - 40s 88ms/step - loss: 1.3085 - accuracy: 0.6639 - val_loss: 1.3589 - val_accuracy: 0.6500\n",
            "Epoch 6/200\n",
            "450/450 [==============================] - 40s 89ms/step - loss: 1.1498 - accuracy: 0.7093 - val_loss: 1.2437 - val_accuracy: 0.6901\n",
            "Epoch 7/200\n",
            "450/450 [==============================] - 40s 90ms/step - loss: 1.0364 - accuracy: 0.7403 - val_loss: 1.1784 - val_accuracy: 0.6990\n",
            "Epoch 8/200\n",
            "450/450 [==============================] - 40s 89ms/step - loss: 0.9451 - accuracy: 0.7631 - val_loss: 1.1599 - val_accuracy: 0.7061\n",
            "Epoch 9/200\n",
            "450/450 [==============================] - 40s 89ms/step - loss: 0.8677 - accuracy: 0.7831 - val_loss: 1.1113 - val_accuracy: 0.7142\n",
            "Epoch 10/200\n",
            "450/450 [==============================] - 44s 97ms/step - loss: 0.7986 - accuracy: 0.8022 - val_loss: 1.1391 - val_accuracy: 0.7182\n",
            "Epoch 11/200\n",
            "450/450 [==============================] - 40s 89ms/step - loss: 0.7345 - accuracy: 0.8156 - val_loss: 1.1443 - val_accuracy: 0.7110\n",
            "Epoch 12/200\n",
            "450/450 [==============================] - 40s 89ms/step - loss: 0.6810 - accuracy: 0.8316 - val_loss: 1.1456 - val_accuracy: 0.7168\n",
            "Epoch 13/200\n",
            "450/450 [==============================] - 40s 90ms/step - loss: 0.6272 - accuracy: 0.8429 - val_loss: 1.1514 - val_accuracy: 0.7222\n",
            "Epoch 14/200\n",
            "450/450 [==============================] - 40s 89ms/step - loss: 0.5863 - accuracy: 0.8554 - val_loss: 1.1868 - val_accuracy: 0.7235\n",
            "71/71 [==============================] - 2s 26ms/step - loss: 1.1868 - accuracy: 0.7235\n",
            "\n",
            " Test Accuracy: 0.7235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L-9aGFt_0-B5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}